{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig, BertModel\n",
    "from transformers import AutoTokenizer\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.news_query_vector_dim = 200\n",
    "        self.drop_rate = 0.2\n",
    "        self.news_dim = 256\n",
    "        self.T = 500\n",
    "        self.corpus_path = './docs_filter.tsv'\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TITLE_LEN = 24\n",
    "MAX_BODY_LEN = 512\n",
    "NPRATIO=9\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101527"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(args.corpus_path, encoding='utf-8') as f:\n",
    "    total_lines = f.readlines()\n",
    "len(total_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles, bodies = [], []\n",
    "for line in total_lines:\n",
    "    splited = line.strip('\\n').split('\\t')\n",
    "    titles.append(splited[3])\n",
    "    bodies.append(splited[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self, titles, bodies):\n",
    "        self.titles = titles\n",
    "        self.bodies = bodies\n",
    "        self.len = len(titles)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        select_list = list(range(0, idx)) + list(range(idx+1, self.len))\n",
    "        neg_idx = random.sample(select_list, NPRATIO)\n",
    "        neg_titles = [self.titles[i] for i in neg_idx]\n",
    "        pos_title = self.titles[idx]\n",
    "        titles = [tokenizer(title, max_length=MAX_TITLE_LEN, padding='max_length',\n",
    "                            truncation=True) for title in [pos_title] + neg_titles]\n",
    "        input_titles = np.array([title['input_ids'] + title['attention_mask'] for title in titles])\n",
    "        body = tokenizer(self.bodies[idx], max_length=MAX_BODY_LEN, padding='max_length',\n",
    "                         truncation=True)\n",
    "        input_body = np.array(body['input_ids'] + body['attention_mask'])\n",
    "\n",
    "        label=0\n",
    "        return input_titles, input_body, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_ds = PretrainDataset(titles, bodies)\n",
    "pretrain_dl = DataLoader(pretrain_ds, batch_size=BATCH_SIZE, num_workers=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(emb_size, hidden_size)\n",
    "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch_size, candidate_size, emb_dim\n",
    "            attn_mask: batch_size, candidate_size\n",
    "        Returns:\n",
    "            (shape) batch_size, emb_dim\n",
    "        \"\"\"\n",
    "        bz = x.shape[0]\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "        alpha = torch.exp(alpha)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "        \n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha).squeeze(dim=-1)\n",
    "        return x\n",
    "\n",
    "class NewsEncoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(NewsEncoder, self).__init__()\n",
    "        config_class, model_class = BertConfig, BertModel\n",
    "        self.bert_config = config_class.from_pretrained(\n",
    "            'prajjwal1/bert-small', \n",
    "            output_hidden_states=True)\n",
    "        self.bert_model = model_class.from_pretrained(\n",
    "            'prajjwal1/bert-small', config=self.bert_config)\n",
    "        self.attn = AttentionPooling(self.bert_config.hidden_size, args.news_query_vector_dim)\n",
    "        self.dense = nn.Linear(self.bert_config.hidden_size, args.news_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x: batch_size, word_num * 2\n",
    "            mask: batch_size, word_num\n",
    "        '''\n",
    "        batch_size, num_words = x.shape\n",
    "        num_words = num_words // 2\n",
    "        text_ids = torch.narrow(x, 1, 0, num_words)\n",
    "        text_attmask = torch.narrow(x, 1, num_words, num_words)\n",
    "        word_vecs = self.bert_model(text_ids, text_attmask)[0]\n",
    "        news_vec = self.attn(word_vecs)\n",
    "        news_vec = self.dense(news_vec)\n",
    "        return news_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleBodySimModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(TitleBodySimModel, self).__init__()\n",
    "        self.news_encoder = NewsEncoder(args)\n",
    "        self.loss = nn.CrossEntropyLoss() \n",
    "        \n",
    "    def forward(self, title, body, labels):\n",
    "        '''\n",
    "            title: bz, 1+K, MAX_TITLE_WORD * 2\n",
    "            body: bz, MAX_BODY_WORD * 2\n",
    "            labels: bz\n",
    "        '''\n",
    "        body_emb = self.news_encoder(body)             #bz,emb_dim\n",
    "        bz, candi_num, input_num = title.shape\n",
    "        title = title.reshape(-1, input_num)\n",
    "        title_emb = self.news_encoder(title)\n",
    "        title_emb = title_emb.reshape(bz, candi_num, -1) #bz, 1+K, emb_dim\n",
    "        scores = torch.bmm(title_emb, body_emb.unsqueeze(dim=-1)).squeeze(-1)\n",
    "        \n",
    "        loss = self.loss(scores, labels)\n",
    "        return scores, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TitleBodySimModel(\n",
       "  (news_encoder): NewsEncoder(\n",
       "    (bert_model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 512)\n",
       "        (token_type_embeddings): Embedding(2, 512)\n",
       "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (attn): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=512, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "    (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_model = TitleBodySimModel(args)\n",
    "device = torch.device('cuda')\n",
    "pretrain_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = torch.argmax(y_hat, dim=-1)\n",
    "    tot = y_true.shape[0]\n",
    "    hit = torch.sum(y_true == y_hat)\n",
    "    return hit.data.float() * 1.0 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(\n",
    "    params=pretrain_model.parameters(), lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200db91969ab4a2a98e185bb65883f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3173 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ep in range(1):\n",
    "    loss = 0.0\n",
    "    accuary = 0.0\n",
    "    cnt = 1\n",
    "    tqdm_util = tqdm(pretrain_dl)\n",
    "    pretrain_model.train()\n",
    "    for title,body,labels in tqdm_util: \n",
    "        title = title.to(device)\n",
    "        body = body.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_hat, bz_loss = pretrain_model(title, body, labels)\n",
    "        loss += bz_loss.data.float()\n",
    "        accuary += acc(labels, y_hat)\n",
    "        optimizer.zero_grad()\n",
    "        bz_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if cnt % 10 == 0:\n",
    "            tqdm_util.set_description('ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(cnt * BATCH_SIZE, loss.data / cnt, accuary / cnt))\n",
    "\n",
    "        if cnt % args.T == 0:\n",
    "            ckpt_path = f'./BERT_finetune_{cnt}.pt'\n",
    "            torch.save({'model_state_dict': pretrain_model.state_dict()}, ckpt_path)\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "ckpt_path = './BERT_finetune.pt'\n",
    "torch.save({'model_state_dict': pretrain_model.state_dict()}, ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Title and Body Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_paths = [\n",
    "    './BERT_finetune.pt',\n",
    "    './BERT_finetune_3000.pt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f73bca855e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data, max_len):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        res = tokenizer(self.data[idx], max_length=self.max_len, pad_to_max_length=True, truncation=True)\n",
    "        return np.array(res['input_ids'] + res['attention_mask'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "title_dataset = NewsDataset(titles, MAX_TITLE_LEN)\n",
    "title_dataloader = DataLoader(title_dataset,\n",
    "                            batch_size=512,\n",
    "                            num_workers=32)\n",
    "\n",
    "body_dataset = NewsDataset(bodies, MAX_BODY_LEN)\n",
    "body_dataloader = DataLoader(body_dataset,\n",
    "                            batch_size=512,\n",
    "                            num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TitleBodySimModel:\n\tMissing key(s) in state_dict: \"news_encoder.bert_model.embeddings.position_ids\", \"news_encoder.bert_model.embeddings.word_embeddings.weight\", \"news_encoder.bert_model.embeddings.position_embeddings.weight\", \"news_encoder.bert_model.embeddings.token_type_embeddings.weight\", \"news_encoder.bert_model.embeddings.LayerNorm.weight\", \"news_encoder.bert_model.embeddings.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.self.query.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.self.query.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.self.key.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.self.key.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.self.value.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.self.value.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.0.intermediate.dense.weight\", \"news_encoder.bert_model.encoder.layer.0.intermediate.dense.bias\", \"news_encoder.bert_model.encoder.layer.0.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.0.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.0.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.0.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.self.query.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.self.query.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.self.key.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.self.key.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.self.value.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.self.value.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.1.intermediate.dense.weight\", \"news_encoder.bert_model.encoder.layer.1.intermediate.dense.bias\", \"news_encoder.bert_model.encoder.layer.1.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.1.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.1.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.1.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.self.query.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.self.query.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.self.key.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.self.key.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.self.value.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.self.value.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.2.intermediate.dense.weight\", \"news_encoder.bert_model.encoder.layer.2.intermediate.dense.bias\", \"news_encoder.bert_model.encoder.layer.2.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.2.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.2.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.2.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.self.query.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.self.query.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.self.key.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.self.key.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.self.value.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.self.value.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.3.intermediate.dense.weight\", \"news_encoder.bert_model.encoder.layer.3.intermediate.dense.bias\", \"news_encoder.bert_model.encoder.layer.3.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.3.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.3.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.3.output.LayerNorm.bias\", \"news_encoder.bert_model.pooler.dense.weight\", \"news_encoder.bert_model.pooler.dense.bias\", \"news_encoder.attn.att_fc1.weight\", \"news_encoder.attn.att_fc1.bias\", \"news_encoder.attn.att_fc2.weight\", \"news_encoder.attn.att_fc2.bias\", \"news_encoder.dense.weight\", \"news_encoder.dense.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jhkim21/coursework/nlp/Tiny-NewsRec/Domian-specific_Post-train.ipynb ì…€ 21\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhi26.snu.ac.kr:7777/home/jhkim21/coursework/nlp/Tiny-NewsRec/Domian-specific_Post-train.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, ckpt_path \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ckpt_paths):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhi26.snu.ac.kr:7777/home/jhkim21/coursework/nlp/Tiny-NewsRec/Domian-specific_Post-train.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     pretrain_model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(ckpt_path))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhi26.snu.ac.kr:7777/home/jhkim21/coursework/nlp/Tiny-NewsRec/Domian-specific_Post-train.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     title_scoring \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhi26.snu.ac.kr:7777/home/jhkim21/coursework/nlp/Tiny-NewsRec/Domian-specific_Post-train.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/envs/SDS/lib/python3.8/site-packages/torch/nn/modules/module.py:1482\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1478\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1479\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1481\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1482\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1483\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1484\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TitleBodySimModel:\n\tMissing key(s) in state_dict: \"news_encoder.bert_model.embeddings.position_ids\", \"news_encoder.bert_model.embeddings.word_embeddings.weight\", \"news_encoder.bert_model.embeddings.position_embeddings.weight\", \"news_encoder.bert_model.embeddings.token_type_embeddings.weight\", \"news_encoder.bert_model.embeddings.LayerNorm.weight\", \"news_encoder.bert_model.embeddings.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.self.query.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.self.query.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.self.key.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.self.key.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.self.value.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.self.value.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.0.intermediate.dense.weight\", \"news_encoder.bert_model.encoder.layer.0.intermediate.dense.bias\", \"news_encoder.bert_model.encoder.layer.0.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.0.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.0.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.0.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.self.query.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.self.query.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.self.key.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.self.key.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.self.value.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.self.value.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.1.intermediate.dense.weight\", \"news_encoder.bert_model.encoder.layer.1.intermediate.dense.bias\", \"news_encoder.bert_model.encoder.layer.1.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.1.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.1.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.1.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.self.query.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.self.query.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.self.key.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.self.key.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.self.value.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.self.value.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.2.intermediate.dense.weight\", \"news_encoder.bert_model.encoder.layer.2.intermediate.dense.bias\", \"news_encoder.bert_model.encoder.layer.2.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.2.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.2.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.2.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.self.query.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.self.query.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.self.key.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.self.key.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.self.value.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.self.value.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.bias\", \"news_encoder.bert_model.encoder.layer.3.intermediate.dense.weight\", \"news_encoder.bert_model.encoder.layer.3.intermediate.dense.bias\", \"news_encoder.bert_model.encoder.layer.3.output.dense.weight\", \"news_encoder.bert_model.encoder.layer.3.output.dense.bias\", \"news_encoder.bert_model.encoder.layer.3.output.LayerNorm.weight\", \"news_encoder.bert_model.encoder.layer.3.output.LayerNorm.bias\", \"news_encoder.bert_model.pooler.dense.weight\", \"news_encoder.bert_model.pooler.dense.bias\", \"news_encoder.attn.att_fc1.weight\", \"news_encoder.attn.att_fc1.bias\", \"news_encoder.attn.att_fc2.weight\", \"news_encoder.attn.att_fc2.bias\", \"news_encoder.dense.weight\", \"news_encoder.dense.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\". "
     ]
    }
   ],
   "source": [
    "for i, ckpt_path in enumerate(ckpt_paths):\n",
    "    pretrain_model.load_state_dict(torch.load(ckpt_path))\n",
    "    title_scoring = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids in tqdm(title_dataloader):\n",
    "            input_ids = input_ids.cuda()\n",
    "            news_vec = pretrain_model.news_encoder(input_ids)\n",
    "            news_vec = news_vec.to(torch.device(\"cpu\")).detach().numpy()\n",
    "            title_scoring.extend(news_vec)\n",
    "\n",
    "    title_scoring = np.array(title_scoring)\n",
    "    with open(f'./teacher_title_emb_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(title_scoring, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ckpt_path in enumerate(ckpt_paths):\n",
    "    pretrain_model.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "    body_scoring = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids in tqdm(body_dataloader):\n",
    "            input_ids = input_ids.cuda()\n",
    "            news_vec = pretrain_model.news_encoder(input_ids)\n",
    "            news_vec = news_vec.to(torch.device(\"cpu\")).detach().numpy()\n",
    "            body_scoring.extend(news_vec)\n",
    "\n",
    "    body_scoring = np.array(body_scoring)\n",
    "    with open(f'./teacher_body_emb_{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(body_scoring, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('SDS': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8faebe5a2c40504fb7c09b62ab9b3c49a32858b967d3499384ad8b14220ec2ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
